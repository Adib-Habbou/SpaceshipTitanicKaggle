{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importation des données"
      ],
      "metadata": {
        "id": "IOmrf-CvF9LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "m4IIrtUR6PIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Qs8Pgi1166"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"final_train.csv\", index_col=[0])\n",
        "test = pd.read_csv(\"final_test.csv\", index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "Oc6mLZ4Z3Tp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Séparation et Encodage"
      ],
      "metadata": {
        "id": "OJgnEUIwGAqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparation des données en train (80%) et test (20%)\n",
        "X = train[[\"PassengerId\", \"Solo\", \"FamilySize\", \"HomePlanet\", \"CryoSleep\", \n",
        "           \"CabinDeck\", \"CabinNum\", \"CabinSide\", \"Destination\", \"Age\", \n",
        "           \"AgeRange\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \n",
        "           \"Spa\", \"VRDeck\", \"Expenses\", \"Spending\", \"Name\"]]\n",
        "y = train[\"Transported\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "metadata": {
        "id": "k_OT67JW28cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création une correspondance entre les noms uniques et des entiers uniques\n",
        "names = pd.concat([X, test], axis=0)['Name'].unique()\n",
        "name_to_int = {name: i for i, name in enumerate(names)}\n",
        "\n",
        "# Mise en correspondance la colonne \"Name\" \n",
        "X_train['Name'] = X_train['Name'].map(name_to_int)\n",
        "X_test['Name'] = X_test['Name'].map(name_to_int)\n",
        "test['Name'] = test['Name'].map(name_to_int)"
      ],
      "metadata": {
        "id": "4ZnNpFWe7B3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instanciation des objets LabelEncoder\n",
        "le_homeplanet = LabelEncoder()\n",
        "le_cabindeck = LabelEncoder()\n",
        "le_cabinside = LabelEncoder()\n",
        "le_destination = LabelEncoder()\n",
        "\n",
        "# Transformation des variables qualitatives en numériques à l'aide de label encoding\n",
        "X_train['HomePlanet'] = le_homeplanet.fit_transform(X_train['HomePlanet'].astype(str))\n",
        "X_train['CabinDeck'] = le_cabindeck.fit_transform(X_train['CabinDeck'].astype(str))\n",
        "X_train['CabinSide'] = le_cabinside.fit_transform(X_train['CabinSide'].astype(str))\n",
        "X_train['Destination'] = le_destination.fit_transform(X_train['Destination'].astype(str))\n",
        "\n",
        "# Transformation des données de test\n",
        "X_test['HomePlanet'] = le_homeplanet.transform(X_test['HomePlanet'].astype(str))\n",
        "X_test['CabinDeck'] = le_cabindeck.transform(X_test['CabinDeck'].astype(str))\n",
        "X_test['CabinSide'] = le_cabinside.transform(X_test['CabinSide'].astype(str))\n",
        "X_test['Destination'] = le_destination.transform(X_test['Destination'].astype(str))\n",
        "\n",
        "# Transformation des données de test pour submissions\n",
        "test['HomePlanet'] = le_homeplanet.transform(test['HomePlanet'].astype(str))\n",
        "test['CabinDeck'] = le_cabindeck.transform(test['CabinDeck'].astype(str))\n",
        "test['CabinSide'] = le_cabinside.transform(test['CabinSide'].astype(str))\n",
        "test['Destination'] = le_destination.transform(test['Destination'].astype(str))"
      ],
      "metadata": {
        "id": "cdvrbdvLBGgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "nWOcmfw7EX5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recherche des hyperparamètres"
      ],
      "metadata": {
        "id": "5wPXFX4y5fyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "fvXn1nEY5RDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Paramètres à tester pour le réglage des hyperparamètres\n",
        "param_grid = \n",
        "{\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Initialisation du modèle SVM\n",
        "svm = SVC(random_state=42)\n",
        "\n",
        "# Initialisation GridSearchCV pour ajuster les hyperparamètres du modèle\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "\n",
        "# Fit du modèle en utilisant les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Sauvegarde des meilleurs hyperparamètres trouvés\n",
        "svm_best_param = grid_search.best_params_\n",
        "\n",
        "# Instanciation du modèle avec les meilleurs hyperparamètres\n",
        "svm_optimized = SVC(**grid_search.best_params_)\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "svm_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Utilisation des meilleurs hyperparamètres pour faire des prédictions sur les données de test\n",
        "y_pred = svm_optimized.predict(X_test)\n",
        "\n",
        "# Calcul de l'accuracy du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy SVM:\", accuracy)"
      ],
      "metadata": {
        "id": "Hi3hOmDYVMyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "uBtAB7t85bBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Paramètres à tester pour le réglage des hyperparamètres\n",
        "param_grid = \n",
        "{\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [30, 50, None],\n",
        "    'min_samples_split': [10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle Random Forest\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialisation GridSearchCV pour ajuster les hyperparamètres du modèle\n",
        "grid_search = GridSearchCV(random_forest, param_grid, cv=5)\n",
        "\n",
        "# Fit du modèle en utilisant les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "print(\"Best parameters : \", grid_search.best_params_)\n",
        "\n",
        "# Sauvegarde des meilleurs hyperparamètres trouvés\n",
        "rf_best_param = grid_search.best_params_\n",
        "\n",
        "# Instanciation du modèle avec les meilleurs hyperparamètres\n",
        "random_forest_optimized = RandomForestClassifier(**grid_search.best_params_)\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "random_forest_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Utilisation des meilleurs hyperparamètres pour faire des prédictions sur les données de test\n",
        "y_pred = random_forest_optimized.predict(X_test)\n",
        "\n",
        "# Calcul de l'accuracy du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Random Forest :\", accuracy)"
      ],
      "metadata": {
        "id": "BBEGvCYu_YOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "UNmUJUcaO0Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Paramètres à tester pour le réglage des hyperparamètres\n",
        "param_grid = \n",
        "{\n",
        "    'learning_rate': [1, 0.1, 0.01],\n",
        "    'max_depth': [5, 6, 7],\n",
        "    'max_leaf_nodes': [8, 9, 10],\n",
        "    'min_impurity_decrease': [0.004, 0.005, 0.006],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'n_iter_no_change': [5, 6, 7]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle Gradient Boosting\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Initialiser GridSearchCV pour ajuster les hyperparamètres du modèle\n",
        "grid_search = GridSearchCV(gbc, param_grid, cv=5)\n",
        "\n",
        "# Fit du modèle en utilisant les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "print(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n",
        "\n",
        "# Sauvegarde des meilleurs hyperparamètres trouvés\n",
        "gbc_best_param = grid_search.best_params_\n",
        "\n",
        "# Instanciation du modèle avec les meilleurs hyperparamètres\n",
        "gbc_optimized = GradientBoostingClassifier(**grid_search.best_params_)\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "gbc_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Utilisation des meilleurs hyperparamètres pour faire des prédictions sur les données de test\n",
        "y_pred = gbc_optimized.predict(X_test)\n",
        "\n",
        "# Calcul de l'accuracy du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Gradient Boosting :\", accuracy)"
      ],
      "metadata": {
        "id": "AdblXcMuO3Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "ZBAxATCFQwh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Paramètres à tester pour le réglage des hyperparamètres\n",
        "param_grid = \n",
        "{\n",
        "    'learning_rate': [0.01, 0.02, 0.03],\n",
        "    'max_depth': [305, 307, 310],\n",
        "    'min_child_weight': [4, 5, 6],\n",
        "    'gamma': [4, 5, 6],\n",
        "    'n_estimators': [780, 790, 800],\n",
        "    'alpha': [0.011, 0.012, 0.013]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle XGBoost\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialiser GridSearchCV pour ajuster les hyperparamètres du modèle\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=5)\n",
        "\n",
        "# Fit du modèle en utilisant les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "print(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n",
        "\n",
        "# Sauvegarde des meilleurs hyperparamètres trouvés\n",
        "xgb_best_param = grid_search.best_params_\n",
        "\n",
        "# Instanciation du modèle avec les meilleurs hyperparamètres\n",
        "xgb_optimized = xgb.GradientBoostingClassifier(**grid_search.best_params_)\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "xgb_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Utilisation des meilleurs hyperparamètres pour faire des prédictions sur les données de test\n",
        "y_pred = xgb_optimized.predict(X_test)\n",
        "\n",
        "# Calcul de l'accuracy du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy XGBoost :\", accuracy)"
      ],
      "metadata": {
        "id": "aA-deg4FQy14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ada Boost"
      ],
      "metadata": {
        "id": "Cmt8l6zpa9YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Paramètres à tester pour le réglage des hyperparamètres\n",
        "param_grid = \n",
        "{\n",
        "    'n_estimators': [340, 350, 360],\n",
        "    'learning_rate': [0.1, 0.05, 0.15]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle Ada Boost\n",
        "ada_boost = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Initialisation GridSearchCV pour ajuster les hyperparamètres du modèle\n",
        "grid_search = GridSearchCV(ada_boost, param_grid, cv=5)\n",
        "\n",
        "# Fit du modèle en utilisant les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "print(\"Best parameters : \", grid_search.best_params_)\n",
        "\n",
        "# Sauvegarde des meilleurs hyperparamètres trouvés\n",
        "ada_best_param = grid_search.best_params_\n",
        "\n",
        "# Instanciation du modèle avec les meilleurs hyperparamètres\n",
        "ada_optimized = AdaBoostClassifier(**grid_search.best_params_)\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "ada_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Utilisation des meilleurs hyperparamètres pour faire des prédictions sur les données de test\n",
        "y_pred = ada_optimized.predict(X_test)\n",
        "\n",
        "# Calcul de l'accuracy du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Ada Boost :\", accuracy)"
      ],
      "metadata": {
        "id": "ItDbDXsSa_RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sélection des variables"
      ],
      "metadata": {
        "id": "Vd_ecCGB7XMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concaténation des données d'entraînement et de test\n",
        "X = pd.concat([X_train, X_test], axis=0)\n",
        "y = pd.concat([y_train, y_test], axis=0)"
      ],
      "metadata": {
        "id": "UvOI7GS-7ZYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Sélection des caractéristiques en utilisant la régression logistique avec une régularisation L1\n",
        "lr = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=0)\n",
        "selector = SelectFromModel(lr)\n",
        "selector.fit(X, y)\n",
        "selected_features = X.columns[selector.get_support()]"
      ],
      "metadata": {
        "id": "ofvsOUcm8OwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features"
      ],
      "metadata": {
        "id": "LV-8cfFA9-o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédiction à l'aide des modèles"
      ],
      "metadata": {
        "id": "kdSI9jYJ5ccJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "lC7d4iO_6O4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit du modèle sur l'ensemble des données\n",
        "svm_optimized.fit(X[selected_features], y)\n",
        "# Prédiction avec le modèle\n",
        "svm_pred = svm_optimized.predict(test[selected_features])\n",
        "# Création d'un dataFrame à partir des identifiants des passagers et des prédictions\n",
        "result_svm = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': svm_pred})\n",
        "# Transformation des valeurs booléennes en chaînes de caractères \"True\" ou \"False\"\n",
        "result_svm['Transported'] = result_svm['Transported'].astype(str)\n",
        "result_svm['Transported'] = result_svm['Transported'].replace({'0': 'False', '1': 'True'})\n",
        "# Sauvegarde des résultats dans un fichier CSV\n",
        "result_svm.to_csv('submissions_svm.csv', index=False, columns=['PassengerId', 'Transported'])"
      ],
      "metadata": {
        "id": "U1ID0vv26XB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "adoLeUDc7O5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit du modèle sur l'ensemble des données\n",
        "random_forest_optimized.fit(X[selected_features], y)\n",
        "# Prédiction avec le modèle\n",
        "random_forest_pred = random_forest_optimized.predict(test[selected_features])\n",
        "# Création d'un dataFrame à partir des identifiants des passagers et des prédictions\n",
        "result_random_forest = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': random_forest_pred})\n",
        "# Transformation des valeurs booléennes en chaînes de caractères \"True\" ou \"False\"\n",
        "result_random_forest['Transported'] = result_random_forest['Transported'].astype(str)\n",
        "result_random_forest['Transported'] = result_random_forest['Transported'].replace({'0': 'False', '1': 'True'})\n",
        "# Sauvegarde des résultats dans un fichier CSV\n",
        "result_random_forest.to_csv('submissions_random_forest.csv', index=False, columns=['PassengerId', 'Transported'])"
      ],
      "metadata": {
        "id": "AepkCIXj5Nz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "KB87mqRY7QZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit du modèle sur l'ensemble des données\n",
        "gbc_optimized.fit(X[selected_features], y)\n",
        "# Prédiction avec le modèle\n",
        "gbc_pred = gbc_optimized.predict(test[selected_features])\n",
        "# Création d'un dataFrame à partir des identifiants des passagers et des prédictions\n",
        "result_gbc = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': gbc_pred})\n",
        "# Transformation des valeurs booléennes en chaînes de caractères \"True\" ou \"False\"\n",
        "result_gbc['Transported'] = result_gbc['Transported'].astype(str)\n",
        "result_gbc['Transported'] = result_gbc['Transported'].replace({'0': 'False', '1': 'True'})\n",
        "# Sauvegarde des résultats dans un fichier CSV\n",
        "result_gbc.to_csv('submissions_gbc.csv', index=False, columns=['PassengerId', 'Transported'])"
      ],
      "metadata": {
        "id": "ZUAVdBX46jWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "DNBlgv1P7SSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit du modèle sur l'ensemble des données\n",
        "xgb_optimized.fit(X[selected_features], y)\n",
        "# Prédiction avec le modèle\n",
        "xgb_pred = xgb_optimized.predict(test[selected_features])\n",
        "# Création d'un dataFrame à partir des identifiants des passagers et des prédictions\n",
        "result_xgb = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': xgb_pred})\n",
        "# Transformation des valeurs booléennes en chaînes de caractères \"True\" ou \"False\"\n",
        "result_xgb['Transported'] = result_xgb['Transported'].astype(str)\n",
        "result_xgb['Transported'] = result_xgb['Transported'].replace({'0': 'False', '1': 'True'})\n",
        "# Sauvegarde des résultats dans un fichier CSV\n",
        "result_xgb.to_csv('submissions_xgb.csv', index=False, columns=['PassengerId', 'Transported'])"
      ],
      "metadata": {
        "id": "W1SHb83P6klK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ada Boost"
      ],
      "metadata": {
        "id": "UDEh8B7z7URz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit du modèle sur l'ensemble des données\n",
        "ada_optimized.fit(X[selected_features], y)\n",
        "# Prédiction avec le modèle\n",
        "ada_pred = ada_optimized.predict(test[selected_features])\n",
        "# Création d'un dataFrame à partir des identifiants des passagers et des prédictions\n",
        "result_ada = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': ada_pred})\n",
        "# Transformation des valeurs booléennes en chaînes de caractères \"True\" ou \"False\"\n",
        "result_ada['Transported'] = result_ada['Transported'].astype(str)\n",
        "result_ada['Transported'] = result_ada['Transported'].replace({'0': 'False', '1': 'True'})\n",
        "# Sauvegarde des résultats dans un fichier CSV\n",
        "result_ada.to_csv('submissions_ada.csv', index=False, columns=['PassengerId', 'Transported'])"
      ],
      "metadata": {
        "id": "votd6a2_6lVG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}